---
ID: 316
post_title: EM Algorithm 整理
author: Chin
post_excerpt: ""
layout: post
permalink: 'http://www.tvect.cc/2018/06/25/em-algorithm-%e6%95%b4%e7%90%86/'
published: true
post_date: 2018-06-25 21:56:41
---
[toc]

<h1>The General EM Algorithm</h1>

<h2>算法概述</h2>

给定观测变量 $$X$$, 和隐变量 $$Z$$ 上的联合分布 $$p(X, Z|\\theta)$$, $$\\theta$$是参数. 目标是要关于$$\\theta$$极大化似然函数$$p(X|\\theta)$$

<ol>
<li>为参数 $$\\theta^{old}$$ 赋一个初始值.</li>
<li><strong>E step</strong>
计算 $$p(Z|X, \\theta^{old})$$.</li>
<li><strong>M step</strong>
计算 $$\\theta^{new}$$: $$ \\theta^{new} = arg \\max \\limits_{\\theta} Q(\\theta, \\theta^{old})$$
其中 $$Q(\\theta, \\theta^{old}) = \\sum \\limits_{Z} p(Z|X, \\theta^{old}) \\, ln\\,p(X, Z|\\theta)$$</li>
<li>检查对数似然函数或者参数值的收敛性。
如果不满足收敛准则，那么令 $$ \\theta^{new} \\leftarrow \\theta^{old}$$.然后，回到第2步，继续.</li>
</ol>

<h2>算法有效性/收敛性证明</h2>

<h3>证明1</h3>

要证明EM算法的有效性/收敛性, 只需要证明每一次迭代可以保证 $$log\\,p(X|\\theta^{i+1}) = L(X|\\theta^{i+1}) \\ge L(X|\\theta^{i})$$

<strong>证明如下：</strong>

$$L(X|\\theta) = log\\,p(X|\\theta) = log \\frac {p(X, Z|\\theta)}{p(Z|X, \\theta)} = log \\, p(X, Z|\\theta) - log \\, p(Z|X, \\theta)$$

等式两边同时关于$$p(Z|X, \\theta^{old})$$做积分有：

$$
\\begin{aligned}
log \\, p(X|\\theta) & = \\int p(Z|X, \\theta^{old})log\\,p(X|\\theta) \\,dZ\\\\
& = \\int p(Z|X, \\theta^{old}) log\\,p(X, Z|\\theta) \\, dZ - p(Z|X, \\theta^{old}) log\\,p(Z|X, \\theta) \\, dZ \\\\
& = Q(\\theta, \\theta^{old}) - \\int p(Z|X, \\theta^{old}) log\\,p(Z|X, \\theta) \\, dZ
\\end{aligned}
$$

下面比较 $$ L(\\theta^{new})$$ 和 $$L(\\theta^{old})$$, 有:
$$
L(\\theta^{new}) - L(\\theta^{old}) = Q(\\theta^{new}, \\theta^{old}) - Q(\\theta^{old}, \\theta^{old}) + \\int p(Z|X,\\theta^{old}) log\\frac{p(Z|X, \\theta^{old})}{p(Z|X, \\theta^{new})} \\,dZ
$$

根据 $$\\theta^{new}$$的定义, 可以知道 $$Q(\\theta^{new}, \\theta^{old}) - Q(\\theta^{old}, \\theta^{old}) \\ge 0$$

根据 KL 距离的非负性, 可以知道 $$\\int p(Z|X,\\theta^{old}) log\\frac{p(Z|X, \\theta^{old})}{p(Z|X, \\theta^{new})} \\,dZ = KL(p(Z|X, \\theta^{old}), p(Z|X, \\theta^{new})) \\ge 0$$

综上,有 $$L(\\theta^{new}) - L(\\theta^{old}) \\ge 0$$, 收敛性得证.

<h3>证明2</h3>

与前一种证明类似，可以看到:
$$L(X|\\theta) = log\\,p(X|\\theta) = log \\frac {p(X, Z|\\theta)}{p(Z|X, \\theta)} = log \\, \\frac {p(X, Z|\\theta)}{q(Z)} + log \\, \\frac{q(Z)}{p(Z|X, \\theta)}$$

其中 $$q(Z)$$ 是引入的一个关于 $$Z$$ 的分布. 两边同时关于 $$q(Z)$$ 求积分, 得到:

$$
\\begin{aligned}
log \\, p(X|\\theta) & = \\int q(Z) \\, log\\,p(X|\\theta) \\,dZ\\\\
& = \\int q(Z) log\\,\\frac {p(X, Z|\\theta)}{q(Z)} + q(Z) log\\, \\frac {q(Z)} {p(Z|X, \\theta)} \\, dZ \\\\
& = \\int q(Z) log\\,\\frac {p(X, Z|\\theta)}{q(Z)} \\, d(Z) + KL(q(Z), p(Z|X, \\theta)) \\\\
& = F(q, \\theta) + KL(q(Z), p(Z|X, \\theta))
\\end{aligned}
$$

EM 算法可以视为 通过优化 $$L(X|\\theta)$$ 的下界 $$F(q, \\theta)$$, 来达到优化 $$L(X|\\theta)$$ 的目的.

<ul>
<li>在 <strong>E-step</strong>: 固定 $$F(q, \\theta)$$ 中的 $$\\theta$$, 关于 $$q(Z)$$ 做优化.
因为 $$L(X|\\theta)$$ 是 $$F(q, \\theta)$$ 的上界, 且与 $$q(Z)$$ 无关, 容易看到, 在 $$q(Z) = p(Z|X, \\theta)$$时, $$F(q, \\theta)$$ 会取得最大值，即为 $$L(X|\\theta)$$.</p></li>
<li><p>在 <strong>M-step</strong>: 固定 $$F(q, \\theta)$$ 中的 $$\\q(z)$$, 关于 $$\\theta$$ 做优化.
$$ \\theta = arg \\max \\limits_{\\theta} \\int q(Z) log\\,\\frac {p(X, Z|\\theta)}{q(Z)} \\, d(Z) = arg \\max \\limits_{\\theta} \\int p(Z|X, \\theta^{old}) log\\, p(X, Z|\\theta) \\, d(Z)$$</p></li>
</ul>

<p>整个过程可以用图示表示如下：
<img src="http://www.tvect.cc/wp-content/uploads/2018/06/em-mm.png" alt="" />

<h1>应用</h1>

<h2>KMeans</h2>

<h2>GMM</h2>

<h2>PLSA</h2>

<h1>参考资料</h1>

<ul>
<li>《PRML》 Chapter 09：Mixture Models and EM</li>
</ul>