---
ID: 756
post_title: 小结-20200129
author: chin340823
post_excerpt: ""
layout: post
permalink: https://www.tvect.cn/archives/756
published: true
post_date: 2020-01-29 12:46:23
---
这部分内容整理来源于 Jordan Book：An Introduction to PGMs，Chapter17. The Junction Tree Algorithm 和 Chapter 18. The HMM and State Space Model Revisited.

第17章讲解了 junction tree algorithm, 第18章以 HMM 和 SSM 为例，讲述了如何从 junction tree algorithm 得到 HMM &amp; SSM 中的概率递推公式.

<!--more-->

<h1>Chapter 17. The Junction Tree Algorithm</h1>

对前面提到的 Elimination Algorithm 做抽象，之前关注的是 inference 操作，这里关注的是 inference 操作背后的 data structure。从而提出了 junction tree 这样一种结构。这种结构可以显式的将 graph-theoretic locality 和 efficient probabilisti inference 建立起来联系。

<h2>17.1 From elimination to the junction tree</h2>

<strong>clique tree</strong>: a singly-connected graph in which the nodes are the cliques of an underlying graph.

Every run of the elimination algorithm can be viewed as implicitly creating a clique tree -- the lique tree can be viewed in essence as an "execution trace" of the algorithm.

可以在 clique tree 上添加上其他的结构. 在每条边上加上 separator set（相应端点的 cliques 的交集）

The separator sets are themselves cliques, being the intersection of cliques. These sets provide an explicit representation of the variables referred to by the intermediate factors that pass between cliques.

What we are groping towards, however, is an algorithm that goes beyond the elimination framework by explicitly representing a clique tree as a data structure.

<h2>17.2 Potentials</h2>

<blockquote>
  a directed graph asserts all of the conditional independencies that characterize the moral graph, as well as additional independencies between the parents of a given node in the marginal distribution in which the node is eliminated. Thus the set of probability distributions associated with the directed graph is a subset of the set of probability distributions associated with the moral graph.
  
  If we solve the inference problem for the family of probability distributions associated with the undirected moral graph, we solve it for the family of probability distributions associated with the directed graph as well.
</blockquote>

To summarize, our procedure will be to identify the maximal cliques of an undirected or (moralized) directed graph. We initialize the potential functions associated with these cliques from the potentials and local conditional probabilities on the underlying graph.

<h2>17.3 Introducing evidence</h2>

<ul>
<li>Approach 1.

Our general approach will be to represent conditionals via taking "slices" of the potentials defining the joint probability.</p></li>
</ul>

<p>$$ P(x_H, \bar{x}<em>E) = \frac{1}{Z} \prod_C \psi_C(x</em>{C \cap H}, \bar{x}<em>{C \cap E}) = \frac{1}{Z} \prod_C \tilde{\psi}</em>{C \cap H}(x_{C \cap H}) $$

<ul>
<li>Approach 2.

An equivalent approach to representing conditional probability distributions involves introducing "evidence potentials".

An evidence potential is a delta function, $ \delta(x_E ; \bar{x}_E) $.</p></li>
</ul>

<h2>17.4 Clique trees</h2>

<p>We define a clique tree as a singly-connected graph whose nodes represent members of the clique set $C$.

On each edge of a clique tree we associate a separator set which contains the intersection of the cliques that it links.

Given a clique tree with cliques $C$ and separators $S$ we define the joint probability as follows:

$$ p(x) = \frac{\prod_C \psi_C(x_C)}{\prod_S \psi_S(x_S)} $$

<blockquote>
  the separator potentials do not enlargen the set of joint probability distributions that we can represent. They are essentially a convenience -- they allow us to represent the set of joint probability distributions associated with a graphical model in a more flexible way.
</blockquote>

The new capability that the extended representation has provided is the ability (in principle) to obtain a local representation of marginal probabilities, while maintaining an overall representation of the joint.

<h2>17.5 Local consistency</h2>

初始的 clique potential 为 $ \psi_V, \psi_W $, separator potential 为 $\phi_S$

<ol>
<li>update W based on V (pass information from V to W)</li>
</ol>

$$ \phi_S^{\star} = \sum_{V \setminus S} \psi_V $$

$$ \psi_W^{\star} = \frac{\phi_S^{\star}}{\phi_S} \psi_W $$

注意，在变换前后，联合概率是不变的, 即 $ \frac{\psi_V^{\star}\psi_W^{\star}}{\phi_S^{\star}} = \frac{\psi_V \psi_W}{\phi_S} $

<ol start="2">
<li>update V based on W (pass information from W back to V)</li>
</ol>

$$ \phi_S^{\star \star } = \sum_{W \setminus S} \psi_W^{\star} $$

$$ \psi_V^{\star \star } = \frac{\phi_S^{\star \star}}{\phi_S^{\star}} \psi_V^{\star} $$

注意，做完这两次更新操作之后，the potentials $\psi_V^{\star \star}$ and $ \psi_W^{\star \star} $ are consistent with respect to their intersection $S$, 即有 $ \sum_{V \setminus S} \psi_V^{\star \star} = \phi_S^{\star \star} = \sum_{W \setminus S} \psi_W^{\star \star} $.

<h2>17.6 Propagation in a clique tree</h2>

<strong>要解决的问题</strong>: how to perform the updates so that local consistency obtained between a clique and its neighbor is not ruined by subsequent updates between the clique and other neighbors.

<strong>Message-Passing Protocol</strong>: A clique can send a message to a neighboring clique only when it has received messages from all of its other neighbors.

<strong>以遵循 Message-Passing Protocol 的方式来对 clique tree 做更新, 可以在整个更新过程中保证 clique tree 的 local consistency</strong>

<strong>procedures: CollectEvidence &amp; DistributeEvidence</strong>

<h2>17.7 The junction tree property</h2>

<strong>前面介绍的算法直接应用到 general graphical model 会有问题</strong>：

在某些 graphical model 中，只使用原始图中的 clique 可能并不够（there is no way to choose an elimination ordering such that the elimination cliques are contained within the cliques of the original graph）

What we may fail to achieve is locality -- the clique potentials (and seperator potential) correctly represent the joint probability, but they are not local marginal probabilities.

<strong>The junction tree property</strong>: A clique tree possesses the junction tree property if for every pair of cliques $V$ and $W$ , all cliques on the (unique) path between $V$ and $W$ contain $V \setminus W$ .

A clique tree that possesses the junction tree property is referred to as a <strong>junction tree</strong>.

<strong>In a junction tree, local consistency implies global consistency.</strong>

<strong>In a junction tree, the junction tree algorithm not only achieves global consistency, but it yields the sought-after clique marginals as well.</strong>

<strong>Theorem</strong>

Let the probability $p(x_H ; x_E)$ be represented by the clique potentials $C$ and separator potentials $S$ of a junction tree. When the junction tree algorithm terminates, the clique potentials and separator potentials are proportional to local marginal probabilities. In particular:

$$ \psi_C = p(x_C ; \bar{x}_E) $$

$$ \phi_S = p(x_S; \bar{x}_E) $$

<h2>17.8 Triangulated graph -> Junction tree</h2>

<strong>要解决的问题</strong>: What class of graphs have a junction tree?

<strong>Triangulated graph</strong>

Consider a cycle in an undirected graph. A cycle is <em>chordless</em> if there are no edges between nodes that are not sucessors in the cycle.

A graph is said to be <em>triangulated</em> if there are no chordless cycles in the graph.

<strong>Theorem</strong>: All triangulated graphs have a junction tree.

<h2>17.9 Elimination -> Triangulation</h2>

<strong>要解决的问题</strong>: How do we handle graphs that do not have a junction tree?

<blockquote>
  In this section we show that <em>UndirectedGraphEliminate</em> can be viewed as a procedure for creating a triangulated graph. This result will show us how to deal with nontriangulated graphs within the junction tree framework. It also allows us to demonstrate that the elimination algorithm is a special case of the junction tree algorithm.
</blockquote>

<strong>Theorem</strong>: <em>UndirectedGraphEliminate</em> yields a triangulated graph

elimination algorithm 可以被视为 junction tree algorithm 的一个特例.

考虑计算每个 non-evidence nodes 的边缘分布, 分别使用 elimination algorithm 和 junction tree algorithm 来处理这个问题：

<ol>
<li>elimination algorithm</li>
</ol>

使用 elimination algorithm 会要求对每个不同的 target node 选择不同的 elimination orderings. 不同的 elimination orderings 会产生不同的 elimination cliques, 从而很难共享重用一些中间的 potential.

<ol start="2">
<li>junction tree algorithm</li>
</ol>

选择某一个 elimination ordering (可能不是最优的), 构造一个 triangulated graph. 接下来就可以重用 intermediate potentials, 有效的计算所有 clique marginals.

<h2>17.10 Constructing the junction tree</h2>

<strong>要解决的问题</strong>: how to construct an appropriate clique tree？更具体的，How do we construct a junction tree from a triangulated graph?

<strong>Theorem</strong>: A clique tree T is a junction tree if and only if it is a maximal spanning tree.

<h2>17.11 The Hugin algorithm</h2>

<ol>
<li><strong>Moralization</strong></p></li>
<li><p><strong>Introduction of evidence</strong></p></li>
<li><p><strong>Triangulation</strong>

The graph is triangulated, using one of several possible algorithms. The potential of each clique of the original graph is multiplied onto the potential of a clique that contains the clique.</p></li>
<li><p><strong>Construction of junction tree</strong>

A junction tree is constructed by forming a maximal spanning tree from the cliques of the triangulated graph. Separators are introduced and their potentials are initialized to unity</p></li>
<li><p><strong>Propagation of probabilities</strong>

Computation proceeds in the junction tree via the following update equations:
$$ \phi_S^{\star} = \sum_{V \setminus S} \psi_V $$
$$ \psi_W^{\star} = \frac{\phi_S^{\star}}{\phi_S} \psi_W $$
The updates must respect the Message-Passing Protocol.

Once the algorithm terminates, the clique potentials and separator potentials are proportional to marginal probabilities. Further marginalization can be performed to obtain the probabilities of singleton nodes or other subsets.</p></li>
</ol>

<h2>17.12 The Shafer-Shenoy algorithm</h2>

<p>The Shafer-Shenoy algorithm can be viewed as a variation on the junction tree framework in which no use is made of separator potentials.

Consider the pair of cliques $C_i$ and $C_j$ with separator $S_{ij} = C_i \setminus C_j $, exchange messages via the following equations:

$$ \mu_{ij}(S_{ij}) = \sum_{C_i \setminus S_{ij}} \psi_{C_i} \prod_{k \neq i} \mu_{ki}(S_{ki}) $$

$$ p(C_i) \propto \psi_{C_i} \prod_k \mu_{ki}(S_{ki}) $$

<h2>17.13 Computational complexity</h2>

<h2>17.14 Generalized marginalization</h2>

<blockquote>
  The algebraic machinery that we utilized in deriving the algorithm was elementary|our proofs reposed on the associative, commutative and distributive laws of arithmetic. As we discuss in this section, if we replace the specific algebraic operators that we used with other operators that obey these same laws, we find that the junction tree framework extends readily to a wide class of other problems involving factorized algebraic expressions, of which probabilistic inference is a special case.
</blockquote>

<h3>17.14.1 Maximum probability configurations</h3>

replaing "sum" with "max" in the junction tree algorithm:

$$ \phi_S^{\star} = \max_{V \setminus S} \psi_V $$

$$ \psi_W^{\star} = \frac{\phi_S^{\star}}{\phi_S} \psi_Wv$$

when terminated, $ \psi_C (x_C) = \max_{V \setminus C} p(x)$

<h3>17.14.2 Appendix A. Decomposable &amp; Triangulated &amp; Junction tree</h3>

<strong>Theorem</strong>: The fol lowing are equivalent characterizations of an undirected graph <code>$G$</code>:

<ul>
<li>$G$ is decomposable.</li>
<li>$G$ is triangulated.</li>
<li>$G$ has a junction tree.</li>
</ul>

<h1>Chapter 18. The HMM and State Space Model Revisited</h1>

derive many of the classical algorithms associated with the HMM and the LG-HMM from the point of view of the junction tree framework.

<h1>参考资料</h1>

<ul>
<li><p><a href="">Jordan book: PGM Chapter 17. The Junction Tree Algorithm</a></p></li>
<li><p><a href="">Jordan book: PGM Chapter 18. The HMM and State Space Model Revisited</a></p></li>
</ul>