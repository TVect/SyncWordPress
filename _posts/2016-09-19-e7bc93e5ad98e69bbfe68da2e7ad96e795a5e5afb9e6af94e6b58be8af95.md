---
ID: 12
post_title: 缓存替换策略对比测试
author: chin340823
post_excerpt: ""
layout: post
permalink: https://blog.tvect.cn/?p=12
published: true
post_date: 2016-09-19 13:11:05
---
[toc]

缓存替换策略对比测试
下面首先将Greedy-Dual Size和几种常见的缓存替换策略进行了对比，参与对比的缓存策略有：
RandomDiscard: 随机替换
    FirstInFirstOut: 先进先出
    LeastRecentlyUsed(LRU): 最近最少使用置换算法,也就是首先淘汰最长时间未被使用的项
    LeastFrequentlyUsed(LFU): 最近最不常用置换算法,也就是淘汰一定时期内被访问次数最少的项
之后，也对Greedy-Dual Size中不同的priority计算方式进行了效果测试。

<!--more-->

<hr />

<h1>Greedy-Dual Size简介：</h1>

传统的cache替换，像CPU caches和Virtual Memory处理的都是缓存项大小一致的情况，在我们的场景中，我们要缓存的数据大小是会在很大的范围内变化的，从下面的实验数据中可以看到，我们要缓存的数据尺寸大部分集中在1M，2M以下，但是也会出现几百兆大小的文件。

RandomDiscard，FirstInFirstOut，LeastRecentlyUsed(LRU)，LeastFrequentlyUsed(LFU)，乃至GD算法中都没有考虑到size的影响。

在Greedy-Dual算法中，给每个缓存项赋予权重priority=clock + cost。
在Greedy-Dual Size算法的原始形式中，给每个缓存项赋予权重priority=clock+cost/size。
其中clock用来控制衰老，cost表示获取文件的代价，size表示文件的大小。
从Greedy-Dual和Greedy-Dual Size中对priority的不同赋值，可以看出，Greedy-Dual试图贪婪地使得缓存的每一项价值足够大，而Greedy-Dual Size则试图使得缓存的每一个字节的价值足够大。
所以，直观上感觉，在限定缓存字节上限的情况下，Greedy-Dual Size会比Greedy-Dual表现的更好。

<h2>Greedy-Dual Size基本步骤：</h2>

在本Greedy-Dual Size算法中，缓存权重计算公式设置为 $$ P &#92;left ( f &#92;right ) = Clock + F &#92;times &#92;frac{Cost&#92;left ( f &#92;right )}{Size&#92;left ( f &#92;right )} $$

其基本步骤如下：
1. 如果请求的file在cache中：
更新file访问次数 $$ F&#92;left ( f &#92;right ) = F &#92;left ( f &#92;right ) + 1 $$
更新file缓存权重，并将其权重重新更新到优先级队列中
2. 如果请求的file不在cache中，需要从来源去取file，并
设置file的访问次数为 $$F&#92;left ( f &#92;right ) = 1 $$
计算file的权重，并将其权重插入到优先级队列中
更新cache使用情况： $$Used = Used + Size&#92;left ( f &#92;right )$$
2.1. 如果 $$Used &#92;leqslant Limit$$ :
表明有足够的缓存空间，将file放到缓存中
2.2. 如果 $$Used > Limit$$ :
从优先级队列中选择优先级最低的k个文件, 使得 $$UsedEstimate &#92;leqslant Limit$$ , 其中
$$UsedEstimate = Used - &#92;sum Size&#92;left ( f_{i} &#92;right )$$

<ul>
<li>如果选取的k个文件中包含了file：
file不应该被缓存，从优先队列中剔除file相对应的权重</li>
<li>如果选择的k个文件中不包含file：
更新 $$Clock = max P&#92;left ( f_{i} &#92;right )$$
更新 $$Used = Used - &#92;sum Size&#92;left ( f_{i} &#92;right )$$
其中 $$i &#92;leq k$$
从缓存中移除折k个文件，并从优先队列中剔除这些被移除的文件的权重
把file放到缓存中</li>
</ul>

<h1>实验介绍</h1>

在以下实验中，用limit_size表示测试环境中缓存字节数的上限。
使用了hit_percent和byte_hit_percent来比较不同算法，不同参数下的表现好坏。
hit_percent: 缓存命中比率，即为cache命中数除以数据请求总次数
byte_hit_percent: 字节缓存命中比率，即为cache命中的字节数除以总的请求的字节数

<h2>实验基本数据：</h2>

实验中涉及到的数据包括：真实的每一套设计，每一套设计中包含的模型，每一个模型的大小。
实验数据均来源于真实环境，每次实验中可能会根据需要打乱设计的次序。

在实验数据中，模型size大小的分布情况图如下：
<img src="http://obn75nm65.bkt.clouddn.com/model_size.png" alt="Alt text" />

再将尺寸大小的数据用箱线图展示一下，如下图，下面的为放大后的局部图。
<img src="http://obn75nm65.bkt.clouddn.com/model_size_1.png" alt="Alt text" />
<img src="http://obn75nm65.bkt.clouddn.com/model_size_2.png" alt="Alt text" />
从上面的箱线图可以得到，平均值大约为5M，中位数大约为2M，上四分位数大约为7.5M，下四分位数大约为450K，上边缘大约为17.5M。
可是为什么箱线图告诉我会有这么多异常点？？？

在实验数据中，每个设计案例中含有的模型个数分布如下：
<img src="http://obn75nm65.bkt.clouddn.com/model_dis.png" alt="Alt text" />
同样也对每套设计中包括的模型数进行箱线图展现，结果如下所示，下面的是局部放大之后的图。
<img src="http://obn75nm65.bkt.clouddn.com/model_dis_1.png" alt="Alt text" />
<img src="http://obn75nm65.bkt.clouddn.com/model_dis_2.png" alt="Alt text" />
从下面的箱线图中可以得到，设计中含有的模型数量的平均值大约为29，中位数大约为23，上四分卫数大约为39，下四分位数大约为11，上边缘值大约为81，下边缘值大约为1。
不过还是感觉有很多异常值。

<h2>实验一：测试以上几种算法在不同的limit_size情况下，缓存命中率，缓存字节命中率的差别</h2>

实验环境：
总的请求个数为269962
去重后的请求个数为：8725
总的请求数据字节总数为：1 065 274 095 532byte，约为1TB
去重后的数据字节总数为：46 420 192 764byte，约为43.23GB
实验结果：
五种缓存替换算法，在不同的limit_size下，对应的缓存命中率hit_percent图示如下：
<img src="http://obn75nm65.bkt.clouddn.com/hit-limit.png" alt="Alt text" />

五种缓存替换算法，在不同的limit_size下，对应的字节缓存命中率byte_hit_percent图示如下：
<img src="http://obn75nm65.bkt.clouddn.com/bytehit-limit.png" alt="Alt text" />
实验结论：
通过以上两幅图，
横向来看，随着limit_size的增大，不同算法的两种命中率都有相应的提高。
纵向来看，GDS基本要优于LFU和LRU，而LFU和LRU又比Random和FIFO效果要好。

<h2>实验二：测试GDS算法中，缓存项的不同priority计算方案对结果的影响</h2>

实验中涉及到的priority计算方案有以下几种：

<pre><code class="language-python ">def calc_priority_1(clock, freq, size):
    cost = 1
    return clock + freq * cost

def calc_priority_2(clock, freq, size):
    cost = 2 + size/536
    return clock + freq * cost

def calc_priority_3(clock, freq, size):
    cost = 1
    return clock + freq * cost / math.log(size)

def calc_priority_4(clock, freq, size):
    cost = 2 + size/536
    return clock + freq * cost / math.log(size)

def calc_priority_5(clock, freq, size):
    cost = 1
    return clock + freq * cost/float(size)

def calc_priority_6(clock, freq, size):
    cost = 2 + size/536
    return clock + freq * cost/float(size)
</code></pre>

结果统计：
<img src="http://obn75nm65.bkt.clouddn.com/priority-hit.png" alt="Alt text" />
<img src="http://obn75nm65.bkt.clouddn.com/priority-bytehit.png" alt="Alt text" />

结果分析：
从hit_percent来看，method4和method2缓存命中率最低，从计算公式可以看到，这两种计算方法都比较倾向于缓存size较大的数据项，从而导致了在limit_size的限制下，缓存的数据项数目会比较少，导致缓存命中率较低。method5的缓存命中率最高，因为method5中倾向于缓存size较小的数据，导致缓存项会比较多，缓存命中率会相对比较高。
<img src="http://obn75nm65.bkt.clouddn.com/priority-bytehit_detail.png" alt="Alt text" />

从上边这张对 byte_hit_precent 进行放大的图中来看，
method5，method4，method2 相对于其他三种效果较差。

<h1>参考资料：</h1>

《Improving WWW proxies performance with Greedy-Dual-Size-Frequency caching policy》Ludmila Cherkasova
《基于WEB代理的访问控制网关系统研究与实现》张鑫
《Web缓冲存储器算法Greedy DualSize的分析与改进》杨相生