---
ID: 548
post_title: >
  用深度学习做关系抽取文献整理-远程监督类方法
author: Chin
post_excerpt: ""
layout: post
permalink: 'http://blog.tvect.cc/2018/07/13/%e7%94%a8%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%81%9a%e5%85%b3%e7%b3%bb%e6%8a%bd%e5%8f%96%e6%96%87%e7%8c%ae%e6%95%b4%e7%90%86-%e8%bf%9c%e7%a8%8b%e7%9b%91%e7%9d%a3%e7%b1%bb%e6%96%b9%e6%b3%95/'
published: true
post_date: 2018-07-13 14:21:29
---
[toc]

<h1>概述</h1>

这里主要会整理一些用深度学习做关系抽取的方法,下面是一些远程监督类的方法.

<!--more-->

<hr />

<h1>基本方法</h1>

<h2><a href="https://nlp.stanford.edu/pubs/mintz09.pdf">Distant supervision for relation extraction without labeled data</a></h2>

这篇文章中提出了用 Distant Supervision 的方法做关系抽取.

<h3>motivation</h3>

<blockquote>
  The intuition of distant supervision is that any sentence that contains a pair of entities that participate in a known Freebase relation is likely to express that relation in some way. Since there may be many sentences containing a given entity pair, we can extract very large numbers of (potentially noisy) features that are combined in a logistic regression classifier
</blockquote>

<h3>基本流程</h3>

<ul>
<li><strong>数据集</strong>: FreeBase的知识库 + Wikipedia的文章句子.</li>
</ul>

1.2 million Wikipedia articles and 1.8 million instances of 102 relations connecting 940,000 entities.

<ul>
<li><strong>训练</strong>:</li>
</ul>

做NER标注出persons, organizations, locations后, 考虑 Freebase 中某一实体对出现的所有句子, 结合在这些句子上的特征, 构造多分类的logistic分类器(应该是考虑到每个实体对可能会对应着多种关系???)

文章中尝试了 Lexical features 和 Syntactic features.

<ul>
<li><strong>测试&amp;评估</strong>:</li>
</ul>

做NER后,将所有的在同一句话里面出现的实体对作为潜在的关系实例。在该实体对出现的所有句子里面抽取特征，整合这些特征做最后的分类,得出该实体对可能的关系(可能对应着多种关系类别???)。最后会选自前 n 个最有可能的 relation instances.

可以采用heldout或者人工的方式对得到的置信度高的实体关系进行评估.
在 <strong>held-out evaluation</strong> 中, 会为测试集预留一些relation instances和articles. 最后会对测试集 articles 中新发现的 relation instances 和测试集预留的 relation instances 进行比较. 这种方法能免除人工评估的昂贵代价，但是会有 false negative 的问题.
在 <strong>human evaluation</strong> 中, 会为测试集预留一些 articles, 但不需要为测试集预留 relation instances. 最后会使用人工对测试集 articles 中抽取的关系进行打分.

<hr />

<h2><a href="http://www.nlpr.ia.ac.cn/cip/yubochen/yubochenPageFile/emnlp2015zeng.pdf">Distant Supervision for RE via Piecewise CNNs</a></h2>

文章中提到了远程监督面临的两个问题, 并分别予以处理：
1. 假设过于肯定，易招致错误label
    --->>> multi-instance learning
2. 之前的方法在用远程监督获取标注数据的时候会使用手工特征，期间会利用一些nlp tools.可能会招致错误的累积.
    --->>> Piecewise CNN

<h3>方法流程</h3>

<ul>
<li><strong>Vector Representation</strong></li>
</ul>

Word Embeddings + Position Embeddings (Position Features). 类似于前面的 <a href="http://blog.tvect.cc/2018/07/13/用深度学习做关系抽取文献整理-pipeline类方法/#CR-CNN_Classifying_Relations_by_Ranking_with_CNN">CR-CNN</a>,  <a href="http://blog.tvect.cc/2018/07/13/用深度学习做关系抽取文献整理-pipeline类方法/#CR-CNN_Classifying_Relations_by_Ranking_with_CNN">Multi-Level Attention CNNs</a>.

<ul>
<li><strong>PCNNs = Convolution + Piecewise Max Pooling</strong></li>
</ul>

<img src="http://blog.tvect.cc/wp-content/uploads/2018/07/pcnn.png" alt="" />

从上面的 PCNN 的图示中可以看到，这一部分是先做了普通的 CNN, 再加上 piecewise max pooling 操作.
所谓的 piecewise max pooling 就是在由 entity 分割处理的三个部分上分别做 max pooling, 这样子可以一定程度上捕获实体间的结构信息。将得到 3*n 个值 concat, 再作用 tanh 函数, 得到最终的一个向量表示 (这个向量的长度与原始的句子长度无关了).

<ul>
<li><strong>Softmax Output</strong></li>
</ul>

基于前一步输出的向量表示，做softmax classifier. 中间会用一些 dropout 的技术.
$$
p(r | m_{i}^{j}) = &#92;frac{exp^{o_{r}}}{&#92;sum_{k=1}^{n}exp(o_{k})}
$$

<ul>
<li><strong>Multi-instance Learning</strong></li>
</ul>

为了缓和远程监督中可能出现的错误标注的问题, 这里结合了 Multi-instance learning.

<blockquote>
  Suppose that there are T bags $${M_{1}, M_{2}, ... , M_{T} }$$ and that the i-th bag contains qi instances $$M_{i} = {m_{i}^{1} , m_{i}^{2} , ... , m_{i}^{qi}}$$. The objective of multi-instance learning is to predict the labels of the unseen bags.
</blockquote>

具体算法流程如下：
<img src="http://blog.tvect.cc/wp-content/uploads/2018/07/multi-instance-learning.png" alt="" />

注意：在multi-instance learning中,学习训练都是基于bag的, 而不是instance的. 我们假定bag的标签是已知的，instance的标签未知，因为是在bag级别做学习预测，可以一定程度上缓解 instance 级别上标签的不确定性问题.

从前面的算法中选择 bag 中最大可能的 instance 的操作中，可以看到，这种方法其实假定的是 bag 里面至少有一个 instance 标签是对的，用 bag 中最有可能正确的 instance 机器标签做训练。（类似于做样本增强, 但只选择了一个最有可能正确的样本）

<hr />

<h2><a href="http://www.nlpr.ia.ac.cn/cip/~liukang/liukangPageFile/AAAI2017.pdf">Distant Supervision for RE with Sentence-level Attention and Entity Descriptions</a></h2>

远程监督的方法中可能会有 wrong label 的问题. 在前面的第一篇论文中，并没有显式的考虑这个问题, 在第二篇论文中而是选择了一个最优可能的有效的 sentence.
这篇文章的贡献在于：
1. 可以选择 multi valid sentences.
2. 添加利用了 entity description, 为关系预测提供了背景知识，同时提升了 entity representation.

<h3>方法流程</h3>

<img src="http://blog.tvect.cc/wp-content/uploads/2018/07/apcnn.png" alt="" />

<ul>
<li><strong>PCNN</strong></li>
</ul>

类似于之前一篇论文中的结构

<ul>
<li><strong>Sentence-level Attention Module</strong></li>
</ul>

期望通过 attention 机制可能为一个 bag 中 valid sentence 赋予较高的权重, invalid sentence 赋予较低的权重.

$$
&#92;begin{aligned}
v_{relation} &amp;= e_{1} - e_{2} &#92;&#92;
&#92;&#92;
&#92;alpha_{i} &amp;= &#92;frac{w_{i}}{&#92;sum_{i=1}^{q} exp(w_{j})} &#92;&#92;
&#92;&#92;
w_{i} &amp;= W_{a}^{T}(tanh [b_{i}; v_{relation}]) + b_{a} &#92;&#92;
&#92;&#92;
&#92;bar{b} &amp;= &#92;sum_{i=1}^{q}&#92;alpha_{i}b_{i}
&#92;end{aligned}
$$

注意：在上面的公式中，使用了 entity1 和 entity2 向量表示的差来表示一个关系实例.

<ul>
<li><strong>Entity Descriptions</strong></li>
</ul>

记 (entity, description) 对为: $$ D = &#92;{(e_{i}, d_{i}) | i = 1, 2, ..., |D|&#92;} $$, 其中 $$e_{i}$$ 和 description 中的 word 可以通过一个 embedding matrix 得到, 向量 $$d_{i}$$ 是由 description 通过卷积得到的. 
在这篇文章中会希望 $$e_{i}$$ 和 $$d_{i}$$ 越接近越好, 定义如下的误差函数:
$$
L_{e} = &#92;sum_{i=1}^{|D|} ||e_{i} - d_{i}||_{2}^{2}.
$$

<ul>
<li><strong>Training Objective</strong></li>
</ul>

给定 N 个 bags $$&#92;{B_{1}, ..., B_{n}&#92;}$$, 相应的 label 为 $$&#92;{r_{1}, ..., r_{n}&#92;}$$. Loss 函数定义如下：

$$
&#92;begin{aligned}
L_{A} &amp;= - &#92;sum_{i=1}^{N} logp(r_{i} | B_{i}, &#92;theta) &#92;&#92;
&#92;&#92;
&#92;min L &amp;= L_{A} + &#92;lambda L_{e}
&#92;end{aligned}
$$

总而言之，这篇文献通过使用 attention 机制，可以支持从 bag 中选取多个 valid sentences, 另外在损失函数中增加了 entity description 的约束.

<hr />

<h1>参考资料</h1>

<ul>
<li><p><a href="https://blog.csdn.net/yimixgg/article/details/80509825">博客：关系抽取总结</a></p></li>
<li><p><a href="https://nlp.stanford.edu/pubs/mintz09.pdf">Distant supervision for relation extraction without labeled data</a></p></li>
<li><p><a href="http://www.nlpr.ia.ac.cn/cip/yubochen/yubochenPageFile/emnlp2015zeng.pdf">Distant Supervision for RE via Piecewise CNNs</a></p></li>
<li><p><a href="http://www.nlpr.ia.ac.cn/cip/~liukang/liukangPageFile/AAAI2017.pdf">Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions</a></p></li>
</ul>