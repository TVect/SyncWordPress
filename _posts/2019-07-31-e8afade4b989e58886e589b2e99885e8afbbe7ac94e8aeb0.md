---
ID: 531
post_title: 语义分割阅读笔记
author: chin340823
post_excerpt: ""
layout: post
permalink: https://www.tvect.cn/archives/531
published: true
post_date: 2019-07-31 09:09:26
---
之前在做蛋白质口袋发现的时候，接触到文章 <a href="https://arxiv.org/abs/1904.06517">Detection of protein-ligand binding sites with 3Dsegmentation</a>, 这篇文章使用语义分割的方法来做口袋发现. 借此机会，学习了一下语义分割的一些方法. 现将近期看的一些语义分割的内容整理如下.

<h2>FCN</h2>

<strong>文献</strong>: <a href="https://arxiv.org/abs/1411.4038">Fully Convolutional Networks for Semantic Segmentation</a>

the first work to train FCNs end-to-end (1) for pixelwise prediction and (2) from supervised pre-training.

这篇文章中使用了跳跃结果来结合了深层的粗略的语义信息和浅层的精细的表征信息.

<blockquote>
  Semantic segmentation faces an inherent tension between semantics and location: global information resolves what while local information resolves where. Deep feature hierarchies jointly encode location and semantics in a local-to-global pyramid. We define a novel “skip” architecture to combine deep, coarse, semantic information and shallow, fine, appearance information
</blockquote>

<img src="https://www.tvect.cn/wp-content/uploads/2019/07/fcn.png" alt="" />

未使用跳跃结构的模型为FCN-32s，它直接将最后一层池化的特征图进行反卷积得到分割图像．原始图像经过FCN模型中的5次池化，图像大小压缩为原来的1/32，因此FCN-32s模型中的最后一层直接对它进行了因子 f 为32的上采样操作，由于上采样倍数过大，输出图像完全无法体现出原始图像的细节，所以结果非常差．

在FCN-16s和FCN-8s中使用了跳跃结构如上图所示，FCN-16s模型将第四次池化后的特征图与第五次池化后的特征图结合，既保留了图像的高阶特征，又不会损失过多的图像细节，得到的分割结果明显好于FCN-32s．FCN-8s模型与FCN-16s模型类似．

以FCN-16s模型为例，具体的融合过程为：首先对最后一个池化后的特征图进行因子为2的上采样操作，转化为2X2的图像，然后再与第四次池化后的2X2的特征图相叠加，最后对叠加后的结果进行因子为16的上采样操作．

<h2>UNet</h2>

<strong>文献</strong>: <a href="https://arxiv.org/abs/1505.04597">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>

<img src="https://www.tvect.cn/wp-content/uploads/2019/07/unet.png" alt="" />

<strong>结构说明</strong>:
1. The architecture consists of a <strong>contracting path</strong> to capture context and a symmetric <strong>expanding path</strong> that enables precise localization.

<ol start="2">
<li>左边的 contracting path 中用的是 valid convolution, 是为了让每次计算的时候有完整的上下文信息.</p></li>
<li><p>右边的 expanding path 中做上采样之后, 会和左侧 contracting path 中相对应的 feature map 做裁剪后再 concat.</p></li>
</ol>

<p><strong>overlap-tile strategy</strong>:

如果我们要预测黄色框内区域（即对黄色的内的细胞进行分割，获取它们的边缘），需要将蓝色框内部分作为输入，如果黄色区域在输入图像的边缘的话，那么缺失的数据使用镜像进行补充。如下图左边图像所示，输入图像周围一圈都进行了镜像补充。

这种做法可以让我们以分块图像作为输入而不是整个图像作为输入. 这种策略在处理大的图像的时候会很有用, 因为会有 GPU memory 的限制.

<img src="https://www.tvect.cn/wp-content/uploads/2019/07/overlap-tile.png" alt="" />

<h2>SegNet</h2>

<strong>文献</strong>： <a href="https://arxiv.org/abs/1511.00561">SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</a>

<strong>代码</strong>： https://github.com/ykamikawa/tf-keras-SegNet.git

<blockquote>
  While several layers of max-pooling and sub-sampling can achieve more translation invariance for robust classification correspondingly there is a loss of spatial resolution of the feature maps.
  Therefore, it is necessary to capture and store boundary information in the encoder feature maps before sub-sampling is performed.
</blockquote>

<img src="https://www.tvect.cn/wp-content/uploads/2019/07/segnet.png" alt="" />

SegNet 和 U-net 结构很类似, 主要区别在于 decoder 阶段. SegNet 利用了相应的 encoder 层池化操作的 index 来做 unsampling, 而 U-net 则是将相应的 encoder 层做融合之后执行反卷积.

<strong>结构说明</strong>:

<ul>
<li>encoder 部分:</li>
</ul>

采用的是 VGG16 的前 13 层卷积网络，每个编码器层都对应一个解码器层，最终解码器的输出被送入softmax 分类器以独立的为每个像素产生类概率.

这里的卷积都是 same 卷积, 保持输入的尺寸, max pooling 操作会使得尺寸减少, 但这里在做 max pooling 的时候会记下相应的 max index, 以便在 decoder 的 upsampling 操作中使用.

<ul>
<li>decoder 部分:</li>
</ul>

如下图所示, Unpooling 时使用相应的 encoder 层保存下来的 index 信息, 直接将数据放回对应位置，后面再接 Conv 训练学习.

tensorflow 中使用 tf.scatter_nd 实现 <code>根据 max pooling indices 做 upsampling</code>

<img src="https://www.tvect.cn/wp-content/uploads/2019/07/unpooing_with_index.png" alt="" />

<h2>DeepLab v1</h2>

<h2>DeepLab v2</h2>

<h2>DeepLab V3</h2>

<h2>DeepLab V3+</h2>

<h1>参考资料</h1>