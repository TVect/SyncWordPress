---
ID: 318
post_title: 常见采样方法整理
author: Chin
post_excerpt: ""
layout: post
permalink: 'http://blog.tvect.cc/2018/08/26/%e5%b8%b8%e8%a7%81%e9%87%87%e6%a0%b7%e6%96%b9%e6%b3%95%e6%95%b4%e7%90%86/'
published: true
post_date: 2018-08-26 22:27:40
---
挖了坑，打算最近总结一下机器学习中常用的采样方法。主要参考资料为 PRML 的第 11 章 Sampling Methods.

<!--more-->

<h1>Introduction</h1>

目的是要 evaluate $$ E[f] = \int_{p(z)} f(z) dz = \int f(z) p(z) dz$$,

在离散变量的情形，积分号替换为求和号.

假定这个期望很复杂，不能通过解析的方法简单求解.

一般做法, 是从分布 p(z) 中采样一些样本，用 $$ \hat{f} = \frac{1}{L} \sum_{i=1}^{L} f(z_{i}) $$ 去逼近 $$E(f)$$

问题在于，在采样过程中，样本可能并不是独立的

<h1>Methods</h1>

假设可以由计算机得到（0,1）均匀分布的随机数z，现在想得到服从任意分布p(y)的随机数y的样本，其中假定y=f(z)。
概率密度变量转换时，为了保证概率相等，要求p(z)dz~=p(y)dy，当然概率密度必须是正的，所以有下式：$$ p(y)=p(z)|\frac{dz}{dy}| $$

为了能得到特定的分布，只要能找到相应的函数 f 即可.

对上式两边求积分: $$ z = \int_{-\inf}^{y} p(y) dy = h(y) $$, 取 $$f = h^{-1}$$, 也即 y 的累积分布函数的逆，即可.

类似的，在多变量的情况下有：$$ p(y_1, ..., y_m) = p(z_1, ..., z_m) | \frac{\partial (z_1, ..., z_m) }{\partial (y_1, ..., y_m)} |$$

例子: 指数分布，柯西分布，正态分布

<h2>rejection sampling</h2>

<h2>importance sampling</h2>

<h2>Markov Chain Monto Carlo</h2>

<h3>Metropolis-Hastings algorithm</h3>

<h3>Gibbs Sampling</h3>

<h2>Slice Sampling</h2>

<h1>Reference</h1>

<ul>
<li>PRML chapter 11. SAMPLING METHODS</li>
</ul>