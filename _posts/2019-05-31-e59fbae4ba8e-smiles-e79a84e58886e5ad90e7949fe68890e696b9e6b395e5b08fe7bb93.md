---
ID: 397
post_title: >
  基于 SMILES
  的分子生成方法小结
author: chin340823
post_excerpt: ""
layout: post
permalink: https://www.tvect.cn/archives/397
published: true
post_date: 2019-05-31 17:33:56
---
这里主要是基于 <a href="https://github.com/molecularsets/moses">moses</a>, 介绍并列举常见的一些基于SMILES的分子生成方法。

<h1>任务介绍</h1>

<img src="https://www.tvect.cn/wp-content/uploads/2019/05/3fbd5999bff2a6a76cdd154947e8f4e2.png" alt="" />

这里主要考虑的是分子生成的问题, 更具体的说这篇博客当中主要针对的都是生成 SMILES 的问题.

SMILES 将一个分子表示成一个字符串, 如上图中的 <code>Strings</code>. 所以, 可以把 SMILES 生成的问题当做一个文本生成的问题.

<h1>评价指标</h1>

<ul>
<li>Fragment similarity (Frag)</li>
</ul>

这个指标衡量了两堆分子在化学片段层面的相似性.

$Frag(G; R) = 1 − cos(f_G; f_R)$

其中, $f_G$ ($f_R$) 表示了是生成的分子集合中(参考的分子集合中) 分子片段的频率统计向量. 这里的分子片段可以利用 rdkit 直接计算得到.

<ul>
<li>Scaffold similarity (Scaff)</li>
</ul>

这个指标衡量了两堆分子的 scaffolds (骨架?)出现频率的相似性.

$Scaff(G; R) = 1 − cos(s_G; s_R)$

其中, $s_G$ ($s_R$) 表示了是生成的分子集合中(参考的分子集合中) 分子 scaffold 的频率统计向量. 这里的 scaffold 可以利用 rdkit 直接计算得到.

<ul>
<li>Nearest neighbor similarity (SNN)</li>
</ul>

这个指标衡量了生成分子集和参考分子集在化学结构层面(以 fingerprint 表示)的相似性.

$ SNN(G; R) = \frac{1}{|G|} \sum_{m_G \in G} \max_{m_R \in R} T(m_G, m_R) $

其中,  $m_R$ 和 $m_G$ 是分子的 fingerprint 表示. $T(.;.)$ 表示的两个分子的 Tanimoto 相似性. 这个指标也就是计算 每个产生的分子和参考分子集中最近的分子, 然后做平均.

<ul>
<li>Internal diversity (IntDivp)</li>
</ul>

这个指标衡量了生成分子集中分子多样性, 它主要检测了生成式模型当中的 model collapse 现象.

$ IntDiv_p(G) = 1 − \sqrt[p]{\frac{1}{|G|^2} \sum_{m_1, m_2 \in G}T(m_1, m_2)^p} $

<ul>
<li>Fréchet ChemNet Distance (FCD)</li>
</ul>

$ FCD(G; R) = || \mu_G − \mu_R ||^2 + Tr(\sum_G + \sum_R − 2(\sum_G \sum_R) ^{1/2}) $

其中, $\mu$, $\sum$ 是深度神经网络 ChemNet 倒数第二层向量计算得到的均值向量和协方差矩阵. ChemNet 是用来预测生物活性的. 这个指标反映了生物性质和化学性质上一些相似性.

<ul>
<li>Auxiliary Metrics</li>
</ul>

包括 Molecular weight (MW), LogP, Synthetics Accessibility Score(SA), Quantitative Estimation of Drug-likeness (QED), Natural Product-likeness Score (NP). 这些指标都通常用来表示小分子药物发现的质量.

<h1>常见方法</h1>

<h2>Character-level Recurrent Neural Network (CharRNN)</h2>

<blockquote>
  treats the task of generating SMILES as a language model attempting to learn the statistical structure of SMILES syntax by training it on a large corpus of SMILES.
</blockquote>

<img src="https://raw.githubusercontent.com/molecularsets/moses/master/images/CharRNN.png" alt="CharRNN" />

<h2>Variational Autoencoder (VAE)</h2>

<img src="https://raw.githubusercontent.com/molecularsets/moses/master/images/VAE_AAE.png" alt="VAE" />

具体的 VAE 的原理部分可以参考 <a href="https://www.tvect.cn/archives/304">博客: VAE 笔记</a>

下面给出的是 Moses 中将 VAE 用于分子生成(或者文本生成)的做法:

<strong>训练过程</strong>

<ul>
<li>encoder
输入SMILES表示, 经过 RNN 得到最后的 hidden state, hidden state 再经过前向神经网络分别得到 $\mu$ 和 $\log \, \sigma^2$, 并从$ \mathcal N (\mu, \sigma^2)$ 中采样一个 $z$.</p></li>
<li><p>decoder
decoder 也是使用一个 RNN.
将 $z$ 丢到前向神经网络中得到 $h_0$, 将 $h_0$ 作为 decoder RNN 的 initial state.
将 $z$ 重复多次, 和原始输入SMILES的 embedding 表示拼接, 得到 $x_{input}$ 作为 decoder RNN 每一步的输入.
decoder 的目标是下一个 token (所以需要对 SMILES 前后添加 sos 和 eos 标志), 损失函数为 cross_entropy.</p></li>
</ul>

<p><strong>采样生成新样本过程</strong>
从标准正态分布中采样一个 $z$. 后面操作和训练时的decoder稍有不同.

<ol>
<li>decoder RNN 的第一个时间步的输入由 SOS 的embedding表示 和 $h_0$ 拼接得到.</li>
<li>其他时间步的输入由 上一个时间步解码采样的结果的表示 和 $h_0$ 拼接得到.</li>
<li>解码过程持续到产生 EOS 为止.</li>
</ol>

<h2>Adversarial Autoencoder (AAE)</h2>

<img src="https://www.tvect.cn/wp-content/uploads/2019/05/152fc74e46f293f8679c210fc58dfbd2.png" alt="AAE" />

<strong>pretrain 阶段</strong>
训练 AutoEncoder 部分

<strong>train 阶段</strong>
loss 包括： AutoEncoder loss 即 重构的CrossEntropy, generator loss, discriminator loss.

这里用 discriminator 来取代传统 VAE 中的 KL divergence 部分.

<h2>Objective-Reinforced Generative Adversarial Network (ORGAN)</h2>

<img src="https://www.tvect.cn/wp-content/uploads/2019/05/9e043e930923447957bd8de9f238064b.png" alt="ORGAN" />

<strong>工作流程:</strong>

1.<strong>pretrain</strong>

<ul>
<li><strong>pretrain_generator</strong>
input为 seq[:-1], target 为 seq[1:], 损失函数为 CrossEntropy</p></li>
<li><p><strong>pretrain_discriminator</strong>
训练分类器区分 real data, 和 generated data.</p></li>
</ul>

<p><strong>generated data 产生过程:</strong>

构造一个shape为[batch_size, 1] 的 array, 其中元素均为 sos, 丢到 generator 中, 采样产生下一个元素。
再使用刚产生的shape为 [batch_size, 1] 的 array, 作为 generator 的输入, 产生下一个元素 ......
最后将得到的元素拼接起来，得到一个 shape 为 [batch_size, max_length] 的 samples.

2.<strong>train_policy_gradient</strong>

<ul>
<li><strong>训练 generator</strong></li>
</ul>

使用 RL 中的 policy gradient 方法.

模拟分子生成过程, 第一步输入 sos, 丢到RNN, 采样得到下一个 token, 根据此 token 往后继续生成一批完整序列, 计算每个完整序列的 Reward $R(Y_{1:T})$, 将这些Reward作平均作为 state-action value.

更通用的来说, 对于每一个 $Y_{1:t}$, 将其扩展依照前面 generated data 的过程扩展直至 eos 或达到指定长度. 扩展 n_rollouts 次，最后做平均，即为 $Q(Y_{1:t-1}; y_t)$。（Monte Carlo search）

其中,完整序列的 Reward $R(Y_{1:T})$ 通过两部分加权得到：

(1) obj_rewards $O_{i}(Y_{1:t})$: 来源于自定义的一些评估函数, 判断分子式是否合理.

(2) discriminator_rewards $D_{\phi}(Y_{1:t})$: 来源于 discriminator 的评估得分.

即 $R(Y_{1:t}) = \lambda D_{\phi}(Y_{1:t}) + (1 - \lambda) O_{i}(Y_{1:t})$

求得 $Q$ 之后, 后续即可使用 Policy Gradient 进行更新训练.

<blockquote>
  If $\lambda = 0$ the model ignores D and becomes a "naive" RL algorithm, whereas if $\lambda = 1$ it is simply a SeqGAN model.
</blockquote>

<ul>
<li><strong>训练 discriminator</strong></li>
</ul>

同预训练中的 pretrain_discriminator

<h1>常见方法的效果</h1>

参见 <a href="https://github.com/molecularsets/moses/blob/master/README.md">moses README</a>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th rowspan="2">Model</th>
      <th rowspan="2">Valid (↑)</th>
      <th rowspan="2">Unique@1k (↑)</th>
      <th rowspan="2">Unique@10k (↑)</th>
      <th colspan="2">FCD (↓)</th>
      <th colspan="2">SNN (↑)</th>
      <th colspan="2">Frag (↑)</th>
      <th colspan="2">Scaf (↑)</th>
      <th rowspan="2">IntDiv (↑)</th>
      <th rowspan="2">IntDiv2 (↑)</th>
      <th rowspan="2">Filters (↑)</th>
    </tr>
    <tr>
      <th>Test</th>
      <th>TestSF</th>
      <th>Test</th>
      <th>TestSF</th>
      <th>Test</th>
      <th>TestSF</th>
      <th>Test</th>
      <th>TestSF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><i>Train</i></td>
      <td><i>1.0</i></td>
      <td><i>1.0</i></td>
      <td><i>1.0</i></td>
      <td><i>0.008</i></td>
      <td><i>0.4755</i></td>
      <td><i>0.6419</i></td>
      <td><i>0.5859</i></td>
      <td><i>1.0</i></td>
      <td><i>0.9986</i></td>
      <td><i>0.9907</i></td>
      <td><i>0.0</i></td>
      <td><i>0.8567</i></td>
      <td><i>0.8508</i></td>
      <td><i>1.0</i></td>
    </tr>
    <tr>
      <td>CharRNN</td>
      <td>0.8088</td>
      <td><b>1.0</b></td>
      <td><b>0.9996</b></td>
      <td>0.355</td>
      <td>0.8995</td>
      <td>0.5362</td>
      <td>0.5137</td>
      <td>0.9988</td>
      <td>0.9963</td>
      <td>0.8817</td>
      <td><b>0.1398</b></td>
      <td>0.8547</td>
      <td>0.8488</td>
      <td>0.9751</td>
    </tr>
    <tr>
      <td>AAE</td>
      <td>0.9965</td>
      <td><b>1.0</b></td>
      <td>0.995</td>
      <td>0.3945</td>
      <td>1.0003</td>
      <td>0.6197</td>
      <td>0.5747</td>
      <td>0.9952</td>
      <td>0.9939</td>
      <td>0.8655</td>
      <td>0.1001</td>
      <td><b>0.8565</b></td>
      <td>0.8503</td>
      <td><b>0.9974</b></td>
    </tr>
    <tr>
      <td>VAE</td>
      <td>0.9691</td>
      <td><b>1.0</b></td>
      <td>0.9989</td>
      <td><b>0.0844</b></td>
      <td><b>0.5412</b></td>
      <td><b>0.6226</b></td>
      <td><b>0.5766</b></td>
      <td><b>0.9996</b></td>
      <td><b>0.9982</b></td>
      <td><b>0.9331</b></td>
      <td>0.0616</td>
      <td><b>0.8565</b></td>
      <td><b>0.8505</b></td>
      <td>0.9963</td>
    </tr>
    <tr>
      <td>JTN-VAE</td>
      <td><b>1.0</b></td>
      <td><b>1.0</b></td>
      <td>0.9992</td>
      <td>0.4224</td>
      <td>0.9962</td>
      <td>0.5561</td>
      <td>0.5273</td>
      <td>0.9962</td>
      <td>0.9948</td>
      <td>0.8925</td>
      <td>0.1005</td>
      <td>0.8512</td>
      <td>0.8453</td>
      <td>0.9778</td>
    </tr>
  </tbody>
</table>

<h1>参考资料</h1>

<ul>
<li><p><a href="https://arxiv.org/abs/1811.12823">Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models</a></p></li>
<li><p><a href="https://github.com/molecularsets/moses">github: moses</a></p></li>
<li><p><a href="https://arxiv.org/abs/1511.05644">Adversarial Autoencoders</a></p></li>
<li><p><a href="https://arxiv.org/abs/1705.10843">Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models</a></p></li>
</ul>