---
ID: 442
post_title: 文本匹配 notes
author: Chin
post_excerpt: ""
layout: post
permalink: 'http://blog.tvect.cc/2018/07/05/%e6%96%87%e6%9c%ac%e5%8c%b9%e9%85%8d-notes/'
published: true
post_date: 2018-07-05 18:16:20
---
[toc]

<h1>概述</h1>

自然语言文本匹配(NLSM)问题是要比较两个句子, 判断他们之间的关系. 这种技术可以用于判断两个句子是否表示的是同一个意思，或者是判断前提句子是否蕴含假设句子。在QA和IR的任务中，文本匹配可以用于评价query-answer pairs 的相关程度，或者是排序候选答案。在Machine Comprehension 的任务中，文本匹配可以用于matching a passage with a question and pointing out the correct answer span.

有两种类型的深度学习的架构可以用于NLSM。一种是基于 Siamese Network, 另一种是 matching-aggregation 的架构。下面分别做了整理。

<h1>Siamese Architecture</h1>

在这种结构中，同样的 encoder (CNN or RNN ...) 分别作用在两个输入句子上。两个句子会独立的编码成 sentence vectors，之后会基于得到的 sentence vectors 直接做 matching decision。

这种结构很简单很清楚，但是一个显然的缺陷是，siamese 结构并没有在 encoding 阶段显式的考虑两个句子的交互影响，这可能会导致一些重要信息的丢失。

<h2>Siamese Recurrent Architectures for Learning Sentence Similarity</h2>

<img src="http://www.tvect.cc/wp-content/uploads/2018/07/siamese-manhattan.png" alt="" />

本文的结构如上所示, 基本是简单的使用word embedding + lstm + Manhattan distance。

文章中提到，利用 Manhattan distance 做相似度度量。这种简单的相似性度量函数可以迫使lstm层捕获到更多的句子间的语义差别。

另外，文章中有借助Wordnet, 随机替换句子中同义词, 达到数据增加的目的。在训练完成之后，也有做附加的 nonparametric regression step，对预测值进行校准。

<h2>Learning Text Similarity with Siamese Recurrent Networks</h2>

文章中有将Character-level bilstm + siamsese 结构用到job title normalization任务上。

<img src="http://www.tvect.cc/wp-content/uploads/2018/07/siamese-character.png" alt="" />

采用的损失函数如下：

<img src="http://www.tvect.cc/wp-content/uploads/2018/07/siamese-loss.png" alt="" />

<h1>matching-aggregation 架构</h1>

为了处理 Siamese 结构中的问题，这种结构先对句子中 smaller units (such as words or contextual vectors) 进行匹配。匹配结果再经过 aggregate (CNN or LSTM ...)得到 vector, 去做最后的 matching decision.

在做 smaller units 的匹配时，会尝试不同的粒度(word-by-word, phrase-by-sentence) 的匹配。同时也是考虑不同方向的匹配。

<h2>Text Matching as Image Recognition</h2>

文章中将自己的模型结构称之为MatchPyramid. 具体的<strong>模型流程</strong>如下：

<ol>
<li>通过内积,cos,或者其他形式的interaction func,得到初始的 word-word 的matching matrix</li>
<li>对matching matrix 做卷积(+pooling),做多次，得到更高层次(phrase/sentence)的匹配矩阵.</li>
<li>最后使用MLP计算匹配得分，优化cross entropy损失函数</li>
</ol>

<img src="http://www.tvect.cc/wp-content/uploads/2018/07/match-pyramid.png" alt="" />

<h3>Matching Matrix</h3>

为输入的两个句子构造一个 Matching Matrix M. $$M = f(w_{i}, v_{j})$$, 其中$$w_{i}, v_{j}$$ 分别代表两个句子中的第 i 个和第 j 个 word.

可以使用不同的 $$f$$ 来建模两个 word 之间的交互作用，具体的可以尝试示性函数，Cosine, Dot Product 等等.

<h3>Hierarchical Convolution</h3>

基于前一步得到 2-D 的矩阵，把这个矩阵当做图像来做 CNN 处理。

这里为了处理不同长度的文本，采用了 Dynamic pooling strategy， 也就是根据不同的输入长度，调整pooling kernel 大小，保证 pooling 之后得到的大小相同。

<img src="http://www.tvect.cc/wp-content/uploads/2018/07/match-conv.png" alt="" />

<h3>Matching Score</h3>

文章中使用了 MLP 去计算最后的匹配得分。

<h2>A Compare-Aggregate Model for Matching Text Sequences</h2>

文章主要使用了word-level matching，再用 CNN 做 aggregation。其中在做word-level matching 时，尝试了各种的 comparision func 来做匹配。

<h3>模型图示</h3>

模型结构和采用的comparision functions图示如下：
<img src="http://www.tvect.cc/wp-content/uploads/2018/07/comparison-func.png" alt="" />

<h3>模型基本结构细节</h3>

具体的<strong>模型流程</strong>如下：

<ol>
<li>通过lstm或者修正的lstm得到Q,A中每个word对应的表示.</li>
<li>对于A中每个word的表示和Q做attention,每个a可以得到一个相应的h, h是由Q中vector做weighted sum得到的.</li>
<li>对每个(a, h)利用特定的compare func计算比较之后的向量t.</li>
<li>所有的t构成了一个matrix, 对其做TextCNN分类.</li>
</ol>

<h4>Comparision functions</h4>

comparision functions 公式如下：
<img src="http://www.tvect.cc/wp-content/uploads/2018/07/comparision-funcs-detail.png" alt="" />

作者提到，简单的基于 element-wise operations 的comparision function，就有很不错的效果。

<h2>Bilateral Multi-Perspective Matching for Natural Language Sentences</h2>

<h3>模型图示</h3>

<img src="http://www.tvect.cc/wp-content/uploads/2018/07/BiMPM-1024x478.png" alt="" />

<h3>模型基本结构细节</h3>

<ol>
<li>Word Representation Layer
文章中 word vector 由 word embedding 和 lstm 作用之后的 Character embedding 两部分组成。</p></li>
<li><p>Context Representation Layer
使用了 BiLSTM 做编码</p></li>
<li><p>Matching Layer
基于多视角cosine匹配函数构造了四种匹配策略，每一个time step会得到8个vector,再做concat,得到每个时间步的表示. 具体的四种匹配策略会在下面说明。</p></li>
<li><p>Aggregation Layer
这一层用来从两个匹配向量的序列得到一个固定长度的 matching vector. 这里同样使用了BiLSTM。</p></li>
<li><p>Prediction Layer
这一层使用 two layer feed-forward neural network，来得到最后的概率。</p></li>
</ol>

<h4>四种匹配策略</h4>

<p>定义一个 multi-perspective cosine matching function $$f_{m}$$ 来比较两个向量：

$$m = f_{m}(v_{1}, v_{2}; M)$$
$$m_{k} = cosine(W_{k} \\circ v_{1}, W_{k} \\circ v_{2}) $$

上面公式中的 $$ W \\in R^{l \\times d}$$ 是待训练参数, 其中 $$l$$ 表示有 $$l$$ 个视角， 输出的向量 $$m$$ 是 $$l$$ 维的。

基于上述的 matching function $$f_{m}$$， 文章尝试了四种具体的匹配策略：

<ol>
<li>Full-Matching
当前的 word Representation 和另一个句子的最后一个时间步的输出做匹配
<img src="http://www.tvect.cc/wp-content/uploads/2018/07/full_matching.png" alt="" /></p></li>
<li><p>Maxpooling-Matching
当前的 word Representation 和另一个句子的每一个时间步的输出做匹配，最后取每一维的最大值。
<img src="http://www.tvect.cc/wp-content/uploads/2018/07/maxpooling_matching.png" alt="" /></p></li>
<li><p>Attentive-Matching
首先对当前的 word Representation 和另一个句子的每一个时间步的输出算 attention 得分，计算得到一个加权向量。然后对当前的 word Representation 和得到的相应的加权向量做匹配。
<img src="http://www.tvect.cc/wp-content/uploads/2018/07/attentive-matching.png" alt="" /></p></li>
<li><p>Max-Attentive-Matching
与 Attentive-Matching 类似，只不过这里的 attention vector 不是通过加权得到的，而是取的attention 得分最大的相应的向量。后面做匹配是类似的。</p></li>
</ol>

<p>文章中使用了这四种匹配策略，且分别用到前向和后向的序列上，最终在每个 step 得到 8 个 vector, 将这 8 个 vector 拼接，再丢到后面的 Aggregation Layer 中。

<h1>相关资料</h1>

<ul>
<li><p><a href="http://www.mit.edu/~jonasm/info/MuellerThyagarajan_AAAI16.pdf">论文：Siamese Recurrent Architectures for Learning Sentence Similarity</a></p></li>
<li><p><a href="http://aclweb.org/anthology/W/W16/W16-1617.pdf">论文：Learning Text Similarity with Siamese Recurrent Networks</a></p></li>
<li><p><a href="https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning">博客：siamese 框架介绍以及进一步的优化</a></p></li>
<li><p><a href="https://arxiv.org/abs/1602.06359">论文：Text Matching as Image Recognition</a></p></li>
<li><p><a href="https://arxiv.org/abs/1611.01747">A Compare-Aggregate Model for Matching Text Sequences</a></p></li>
<li><p><a href="https://arxiv.org/abs/1702.03814">Bilateral Multi-Perspective Matching for Natural Language Sentences</a></p></li>
</ul>